{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "BASE_DIR = pathlib.Path().resolve().parent\n",
    "DATASET_DIR = BASE_DIR / \"datasets\"\n",
    "EXPORT_DIR = DATASET_DIR / \"exports\"\n",
    "EXPORT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "SPAM_DATASET_PATH = EXPORT_DIR / \"spam-dataset.csv\"\n",
    "\n",
    "ZIPS_DIR = DATASET_DIR / 'zips'\n",
    "ZIPS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "SPAM_SMS_ZIP_PATH = ZIPS_DIR / \"sms-spam-dataset.zip\"\n",
    "SPAM_YOUTUBE_ZIP_PATH = ZIPS_DIR / \"youtube-spam-dataset.zip\"\n",
    "METADATA_EXPORT_PATH = EXPORT_DIR/\"spam-metadata.pkl\"\n",
    "TOEKNIZER_EXPORT_PATH = EXPORT_DIR/\"spam-tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS_SPAM_ZIP = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\"\n",
    "YOUTUBE_SPAM_ZIP = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00380/YouTube-Spam-Collection-v1.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      " 46  198k   46 95232    0     0  95232      0  0:00:02  0:00:01  0:00:01 49548\n",
      "100  198k  100  198k    0     0    99k      0  0:00:02  0:00:02 --:--:-- 97141\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 67  159k   67  108k    0     0   108k      0  0:00:01  0:00:01 --:--:-- 63488\n",
      "100  159k  100  159k    0     0   159k      0  0:00:01  0:00:01 --:--:-- 93466\n"
     ]
    }
   ],
   "source": [
    "!curl $SMS_SPAM_ZIP -o $SPAM_SMS_ZIP_PATH\n",
    "\n",
    "!curl $YOUTUBE_SPAM_ZIP -o $SPAM_YOUTUBE_ZIP_PATH   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPAM_CLASSIFIER_DIR = DATASET_DIR / \"spam-classifier\"\n",
    "SMS_SPAM_DIR = SPAM_CLASSIFIER_DIR / \"spam-sms\"\n",
    "YOUTUBE_SPAM_DIR = SPAM_CLASSIFIER_DIR / \"youtube-spam\"\n",
    "\n",
    "\n",
    "SMS_SPAM_DIR.mkdir(exist_ok=True, parents=True)\n",
    "YOUTUBE_SPAM_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  D:\\data\\Documents\\ai_api\\datasets\\zips\\sms-spam-dataset.zip\n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\spam-sms/SMSSpamCollection  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\spam-sms/readme  \n",
      "Archive:  D:\\data\\Documents\\ai_api\\datasets\\zips\\youtube-spam-dataset.zip\n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/Youtube01-Psy.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/__MACOSX/._Youtube01-Psy.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/Youtube02-KatyPerry.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/__MACOSX/._Youtube02-KatyPerry.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/Youtube03-LMFAO.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/__MACOSX/._Youtube03-LMFAO.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/Youtube04-Eminem.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/__MACOSX/._Youtube04-Eminem.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/Youtube05-Shakira.csv  \n",
      "  inflating: D:\\data\\Documents\\ai_api\\datasets\\spam-classifier\\youtube-spam/__MACOSX/._Youtube05-Shakira.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o $SPAM_SMS_ZIP_PATH -d $SMS_SPAM_DIR\n",
    "!unzip -o $SPAM_YOUTUBE_ZIP_PATH -d $YOUTUBE_SPAM_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_spam_input_path = SMS_SPAM_DIR / \"SMSSpamCollection\" # tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text    source\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...  sms-spam\n",
       "5568   ham               Will ü b going to esplanade fr home?  sms-spam\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...  sms-spam\n",
       "5570   ham  The guy did some bitching but I acted like i'd...  sms-spam\n",
       "5571   ham                         Rofl. Its true to its name  sms-spam"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sms_spam_input_path = SMS_SPAM_DIR / \"SMSSpamCollection\"\n",
    "sms_df = pd.read_csv(sms_spam_input_path, sep='\\t', header=None)\n",
    "sms_df.columns = ['label', 'text']\n",
    "sms_df['source'] = 'sms-spam'\n",
    "sms_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dfs = []\n",
    "for path in YOUTUBE_SPAM_DIR.glob(\"*.csv\"):\n",
    "    raw_df = pd.read_csv(path)\n",
    "    raw_df.rename(columns={\"CLASS\": 'raw_label', \"CONTENT\": \"text\"}, inplace=True)\n",
    "    raw_df['label'] = raw_df['raw_label'].apply(lambda x: \"spam\" if str(x) == \"1\" else \"ham\")\n",
    "    raw_df['raw_source'] = str(path.name)\n",
    "    raw_df['source'] = 'youtube-spam'\n",
    "    df = raw_df.copy()[['label', 'text', 'source']]\n",
    "    my_dfs.append(df)\n",
    "    # print(df.head())\n",
    "\n",
    "yt_df = pd.concat(my_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>youtube-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>youtube-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>youtube-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>youtube-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>youtube-spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text        source\n",
       "0  spam  Huh, anyway check out this you[tube] channel: ...  youtube-spam\n",
       "1  spam  Hey guys check out my new channel and our firs...  youtube-spam\n",
       "2  spam             just for test I have to say murdev.com  youtube-spam\n",
       "3  spam   me shaking my sexy ass on my channel enjoy ^_^ ﻿  youtube-spam\n",
       "4  spam            watch?v=vtaRGgvGtWQ   Check this out .﻿  youtube-spam"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>sms-spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text    source\n",
       "0   ham  Go until jurong point, crazy.. Available only ...  sms-spam\n",
       "1   ham                      Ok lar... Joking wif u oni...  sms-spam\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...  sms-spam\n",
       "3   ham  U dun say so early hor... U c already then say...  sms-spam\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...  sms-spam"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([sms_df, yt_df])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(SPAM_DATASET_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['label'].tolist()\n",
    "texts = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('spam',\n",
       " 'PRIVATE! Your 2004 Account Statement for 07742676969 shows 786 unredeemed Bonus Points. To claim call 08719180248 Identifier Code: 45239 Expires')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[120], texts[120]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'ham', '1': 'spam'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_legend = {\"ham\": 0, \"spam\": 1}\n",
    "label_legend_inverted = {f\"{v}\": k for k,v in label_legend.items()}\n",
    "label_legend_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_as_int = [label_legend[x] for x in labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_legend_inverted[str(labels_as_int[120])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random_idx = random.randint(0, len(labels))\n",
    "\n",
    "assert texts[random_idx] == df.iloc[random_idx].text\n",
    "\n",
    "assert labels[random_idx] == df.iloc[random_idx].label\n",
    "\n",
    "assert label_legend_inverted[str(labels_as_int[random_idx])] == df.iloc[random_idx].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 280\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_as_int_array = np.asarray(labels_as_int)\n",
    "labels_as_int_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels_as_int_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.1.1-cp38-cp38-win_amd64.whl (7.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from scikit-learn) (1.22.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from scikit-learn) (1.8.1)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.1.1 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090335"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainning_data = {\n",
    "    \"X_train\":X_train, \n",
    "    \"X_test\":X_test, \n",
    "    \"y_train\":y_train, \n",
    "    \"y_test\":y_test,\n",
    "    \"max_words\":MAX_NUM_WORDS,\n",
    "    \"max_seq_length\":MAX_SEQ_LENGTH,\n",
    "    \"legend\":label_legend,\n",
    "    \"legend_inverted\":label_legend_inverted\n",
    "}\n",
    "\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "TOEKNIZER_EXPORT_PATH.write_text(tokenizer_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(METADATA_EXPORT_PATH, \"wb\") as f:\n",
    "    pickle.dump(trainning_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "291713af647146e04ac219d946794240e5391d23bed4a06bbd169cf4cac42e79"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
