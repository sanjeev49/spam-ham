{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Using cached boto3-1.24.2-py3-none-any.whl (132 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.2\n",
      "  Using cached botocore-1.27.2-py3-none-any.whl (8.8 MB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from botocore<1.28.0,>=1.27.2->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from botocore<1.28.0,>=1.27.2->boto3) (1.26.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.2->boto3) (1.16.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.24.2 botocore-1.27.2 jmespath-1.0.0 s3transfer-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR = pathlib.Path('/datasets/exports/')\n",
    "#GUIDES_DIR = pathlib.Path(\"/guides/spam-classifier/\")\n",
    "DATASET_CSV_PATH = EXPORT_DIR / 'spam-dataset.csv'\n",
    "TRAINING_DATA_PATH = EXPORT_DIR / 'spam-metadata.pkl'\n",
    "#PART_TWO_GUIDE_PATH = GUIDES_DIR / \"2 - Convert Dataset into Vectors.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p \"$EXPORT_DIR\"\n",
    "!mkdir -p \"$GUIDES_DIR\"\n",
    "!curl \"https://raw.githubusercontent.com/codingforentrepreneurs/AI-as-an-API/main/datasets/exports/spam-dataset.csv\" -o \"$DATASET_CSV_PATH\"\n",
    "!curl \"https://raw.githubusercontent.com/codingforentrepreneurs/AI-as-an-API/main/guides/spam-classifier/2%20-%20Convert%20Dataset%20into%20Vectors.ipynb\" -o \"$PART_TWO_GUIDE_PATH\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "291713af647146e04ac219d946794240e5391d23bed4a06bbd169cf4cac42e79"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
